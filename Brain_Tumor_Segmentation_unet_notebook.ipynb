{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Necessary Imports***"
      ],
      "metadata": {
        "id": "U61mBs3pGD0K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghCou9FjOBLT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVd8ay9KL6uN"
      },
      "source": [
        "***Loading the dataset***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPZgla2uoGRm"
      },
      "outputs": [],
      "source": [
        "#Configuration environment\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = \"vrushali25898\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"12a58cd5ea5950100079afa5fef64042\" # key from the json file\n",
        "\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_YUcHVcoyBv"
      },
      "outputs": [],
      "source": [
        "# extracting the zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/lgg-mri-segmentation.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCxDGh49OMls"
      },
      "outputs": [],
      "source": [
        "# assigning the datapath\n",
        "data_path = '/content/data/kaggle_3m/'\n",
        "\n",
        "# creating a list of files containing the word \"mask\"\n",
        "mask_files = glob('/content/data/kaggle_3m/*/*_mask*')\n",
        "\n",
        "# replacing the mask work by empty string\n",
        "train_files = [file.replace('_mask', '') for file in mask_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqgUviBNndop"
      },
      "outputs": [],
      "source": [
        "# creating a dataframe for further handling the dataset\n",
        "df = pd.DataFrame({\"image_path\": train_files,\n",
        "                   \"mask_path\": mask_files})\n",
        "\n",
        "# diplaying the first 5 rows of dataframe\n",
        "df.head()\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPesqWjQO7ps"
      },
      "outputs": [],
      "source": [
        "# this is a function defined in order to classify the MRI images into yes or no tumor. If the diagnosis value is 1, the brain has tumor otherwise no\n",
        "def diagnosis(mask_path):\n",
        "    value = np.max(cv2.imread(mask_path))\n",
        "    return 1 if value > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXJnLadmnbUm"
      },
      "outputs": [],
      "source": [
        "# the diagnosis column is appended to the dataframe so for us to reconfirm that the function diagnosis works.\n",
        "df['diagnosis'] = list(map(lambda x: diagnosis(x), mask_files))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Histogram plot of classification results based on diagnosis column***"
      ],
      "metadata": {
        "id": "u7FHrCuqGPMR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvC_QCf3QQK2"
      },
      "outputs": [],
      "source": [
        "ax = df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(10,6), color=['blue', 'red'])\n",
        "ax.set_title('Data Distribution')\n",
        "ax.set_ylabel('Total Images', fontsize=15)\n",
        "ax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\n",
        "for i, rows in enumerate(df['diagnosis'].value_counts().values):\n",
        "    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6aFXt6aL-Gm"
      },
      "source": [
        "***Just to make sure that the dataframe is created properly, plotting few of the images and masks***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xASEAzWQTV5"
      },
      "outputs": [],
      "source": [
        "df_positive = df[df['diagnosis']==1].sample(5).values\n",
        "df_negative = df[df['diagnosis']==0].sample(5).values\n",
        "\n",
        "def show_data(df, positive=True):\n",
        "    images = []\n",
        "    masks = []\n",
        "    for data in df:\n",
        "        img = cv2.imread(data[0])\n",
        "        mask = cv2.imread(data[1])\n",
        "        images.append(img)\n",
        "        masks.append(mask)\n",
        "    images = np.hstack(np.array(images))\n",
        "    masks = np.hstack(np.array(masks))\n",
        "    \n",
        "    fig = plt.figure(figsize=(25,25))\n",
        "    if positive:\n",
        "        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n",
        "    else:\n",
        "        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n",
        "    grid[0].imshow(images)\n",
        "    grid[0].set_title('Images', fontsize=15)\n",
        "    grid[0].axis('off')\n",
        "    grid[1].imshow(masks)\n",
        "    grid[1].set_title('Masks', fontsize=15)\n",
        "    grid[1].axis('off')\n",
        "    if positive:\n",
        "        grid[2].imshow(images)\n",
        "        grid[2].imshow(masks, alpha=0.4)\n",
        "        grid[2].set_title('Brain MRI with mask', fontsize=15)\n",
        "        grid[2].axis('off')\n",
        "        \n",
        "show_data(df_positive)\n",
        "show_data(df_negative, positive=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaIxGGFLL1BC"
      },
      "source": [
        "***Pre-Processing the image dataset for us to proceed with U-Net model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLpa0qynQXac"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.10,random_state=42)\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.20,random_state=42)\n",
        "\n",
        "print(df_train.values.shape)\n",
        "print(df_test.values.shape)\n",
        "print(df_val.values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Fixing the constants***"
      ],
      "metadata": {
        "id": "y22xQhzlGsvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLQ1lGW2Qy48"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "EPOCHS = 60\n",
        "BATCH_SIZE = 32\n",
        "learning_rate = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Data Augmentation and train and validation generator***"
      ],
      "metadata": {
        "id": "gqJp5xhlGyFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeS-28--QbNW"
      },
      "outputs": [],
      "source": [
        "def train_generator(data_frame, batch_size, aug_dict):\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    \n",
        "    image_generator = image_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        x_col = \"image_path\",\n",
        "        class_mode = None,\n",
        "        color_mode = \"rgb\",\n",
        "        target_size = (256,256),\n",
        "        batch_size = batch_size,\n",
        "        seed = 2022)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        x_col = \"mask_path\",\n",
        "        class_mode = None,\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = (256,256),\n",
        "        batch_size = batch_size,\n",
        "        seed = 2022)\n",
        "# yeild because to pick data batch waise\n",
        "    for (img, mask) in zip(image_generator, mask_generator):\n",
        "        img, mask = norm_data(img, mask)\n",
        "        yield (img, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_82Dg2IvZL6"
      },
      "outputs": [],
      "source": [
        "# when mask value is 0 it indicates that brain has no tumor and viceversa\n",
        "def norm_data(img, mask):\n",
        "    img = img / 255.\n",
        "    mask = mask / 255.\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0 \n",
        "    return (img, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36aiRCCUQ1z-"
      },
      "outputs": [],
      "source": [
        "train_generator_args = dict(rotation_range=0.2,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            zoom_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            fill_mode='nearest')\n",
        "train_gen = train_generator(df_train, BATCH_SIZE, train_generator_args)\n",
        "    \n",
        "val_gen = train_generator(df_val, BATCH_SIZE, dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD1ZLmi0LucH"
      },
      "source": [
        "***Metrics***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeMGIQYa5baW"
      },
      "source": [
        "**Mathematically dice coefficient is ((2 * |X intersection Y|) / (|X|+|Y|))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SiI0TsjQjho"
      },
      "outputs": [],
      "source": [
        "smoothing_factor = 10\n",
        "# smoothing factor is added to make sure denominator never goes zero and so the result should not be indefinite\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred)\n",
        "    return (2.0 * intersection + smoothing_factor) / (union + smoothing_factor)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    sum_ = K.sum(y_true + y_pred)\n",
        "    jac = (intersection + smoothing_factor) / (sum_ - intersection + smoothing_factor)\n",
        "    return jac"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcfiNG_RLppo"
      },
      "source": [
        "**U-Net without Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6gZew0GYLQB"
      },
      "outputs": [],
      "source": [
        "def conv_block(inp,filters):\n",
        "    x=Conv2D(filters,(3,3),padding='same',activation='relu')(inp)\n",
        "    x=Conv2D(filters,(3,3),padding='same')(x)\n",
        "    x=BatchNormalization(axis=3)(x)\n",
        "    x=Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(inp,filters):\n",
        "    x=conv_block(inp,filters)\n",
        "    p=MaxPooling2D(pool_size=(2,2))(x)\n",
        "    return x,p\n",
        "\n",
        "def decoder_block(inp,filters,concat_layer):\n",
        "    x=Conv2DTranspose(filters,(2,2),strides=(2,2),padding='same')(inp)\n",
        "    x=concatenate([x,concat_layer])\n",
        "    x=conv_block(x,filters)\n",
        "    return x    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv9qydA9YX3p"
      },
      "outputs": [],
      "source": [
        "# Define input layer\n",
        "input_img = Input((IMAGE_SIZE[0], IMAGE_SIZE[1], 3), name='img')\n",
        "\n",
        "# Define UNet model without attention\n",
        "d1,p1=encoder_block(input_img,64)\n",
        "d2,p2=encoder_block(p1,128)\n",
        "d3,p3=encoder_block(p2,256)\n",
        "d4,p4=encoder_block(p3,512)\n",
        "b1=conv_block(p4,1024)\n",
        "e2_=decoder_block(b1,512,d4)\n",
        "e3_=decoder_block(e2_,256,d3)\n",
        "e4_=decoder_block(e3_,128,d2)\n",
        "e5_=decoder_block(e4_,64,d1)\n",
        "outputs = Conv2D(1, (1,1),activation=\"sigmoid\")(e5_)\n",
        "model=Model(inputs=[input_img], outputs=[outputs],name='Unet')\n",
        "\n",
        "# Plot the model architecture \n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPnBme4It3-O"
      },
      "source": [
        "**U-Net with Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZyNDMrct3jJ"
      },
      "outputs": [],
      "source": [
        "def attention_block(l_layer,h_layer): \n",
        "    fg=Conv2D(h_layer.shape[-1],(1,1),padding='same')(l_layer)\n",
        "    fx=Conv2D(h_layer.shape[-1],(1,1),strides=(2,2),padding='same')(h_layer)\n",
        "    x=tf.keras.layers.add([fg,fx])\n",
        "    x=Activation('relu')(x)\n",
        "    x=Conv2D(1,(1,1),padding='same',activation='sigmoid')(x)\n",
        "    x=UpSampling2D(size=(2,2))(x)\n",
        "    x=tf.keras.layers.multiply([h_layer,x])\n",
        "    x=BatchNormalization(axis=3)(x)\n",
        "    return x    \n",
        "\n",
        "def decoder_block_att(inp,filters,concat_layer):\n",
        "    x=Conv2DTranspose(filters,(2,2),strides=(2,2),padding='same')(inp)\n",
        "    concat_layer=attention_block(inp,concat_layer)\n",
        "    x=concatenate([x,concat_layer])\n",
        "    x=conv_block(x,filters)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTxIwz42kSvz"
      },
      "outputs": [],
      "source": [
        "# Define UNet model with attention\n",
        "e2=decoder_block_att(b1,512,d4)\n",
        "e3=decoder_block_att(e2,256,d3)\n",
        "e4=decoder_block_att(e3,128,d2)\n",
        "e5=decoder_block_att(e4,64,d1)\n",
        "outputs_att = Conv2D(1, (1,1),activation=\"sigmoid\")(e5)\n",
        "model_att=Model(inputs=[input_img], outputs=[outputs_att],name='AttentionUnet')\n",
        "# Plot the model architecture\n",
        "plot_model(model_att, to_file='model_architecture_decode_att.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFi1GJSMMlG"
      },
      "source": [
        "***Train Model without Attention***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKROUVLIQ-Gf"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFRPtpKQXfdk"
      },
      "outputs": [],
      "source": [
        "best_path = '/content/data/unet_brainMRI.h5'\n",
        "\n",
        "callbacks = [ModelCheckpoint(best_path, verbose=1, monitor='val_loss', save_best_only=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=5, verbose=1, min_lr=1e-7),\n",
        "            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "447OsJreRAb5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_gen,\n",
        "                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=callbacks,\n",
        "                    validation_data = val_gen,\n",
        "                    validation_steps=len(df_val) / BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm6BLoPDMUs6"
      },
      "source": [
        "***Plotting the trends of train vs validation loss, dice_coeff and iou with respect to increase in number of epochs for the unet model without attention***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hZYrfgJRDLs"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,15))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(model.history.history['loss'], 'b-', label='train_loss')\n",
        "plt.plot(model.history.history['val_loss'], 'r-', label='val_loss')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(model.history.history['iou'], 'b-', label='train_iou')\n",
        "plt.plot(model.history.history['val_iou'], 'r-', label='val_iou')\n",
        "plt.legend(loc='best')\n",
        "plt.title('IoU')\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(model.history.history['dice_coef'], 'b-', label='train_dice_coef')\n",
        "plt.plot(model.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Dice Coef')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Loading the best weights of model without attention***"
      ],
      "metadata": {
        "id": "gyoDaLJeIWpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/data/unet_brainMRI.h5\")"
      ],
      "metadata": {
        "id": "YIXmdnsDIbSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9bDfP1kMYM7"
      },
      "source": [
        "***Evaluation of Model without Attention***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBhX3hbTVsCS"
      },
      "outputs": [],
      "source": [
        "test_gen = train_generator(df_test, BATCH_SIZE, dict())\n",
        "results = model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\n",
        "print(\"Test IOU: \",results[1])\n",
        "print(\"Test Dice Coefficent: \",results[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL7dATo-Vu_Z"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    index=np.random.randint(1,len(df_test.index))\n",
        "    img = cv2.imread(df_test['image_path'].iloc[index])\n",
        "    img = cv2.resize(img ,IMAGE_SIZE)\n",
        "    img = img / 255\n",
        "    img = img[np.newaxis, :, :, :]\n",
        "    pred=model.predict(img)\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(np.squeeze(img))\n",
        "    plt.title('Original Image')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n",
        "    plt.title('Original Mask')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(np.squeeze(pred) > .5)\n",
        "    plt.title('Prediction')\n",
        "    # Save the figure as an image with a unique filename\n",
        "    plt.savefig(f'trend_plot_{i}.png')  # Specify a unique filename for each figure\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3XJq6ZtsyAC"
      },
      "source": [
        "***Train model with Attention***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6FD6UxI2xzf"
      },
      "outputs": [],
      "source": [
        "best_path = '/content/data/unet_brainMRI_att.h5'\n",
        "\n",
        "callbacks = [ModelCheckpoint(best_path, verbose=1, monitor='val_loss', save_best_only=True),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=5, verbose=1, min_lr=1e-7),\n",
        "            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTsPCQCO2qQ_"
      },
      "outputs": [],
      "source": [
        "opt = Adam(learning_rate=learning_rate)\n",
        "model_att.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8JAnOTM21ux"
      },
      "outputs": [],
      "source": [
        "history = model_att.fit(train_gen,\n",
        "                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n",
        "                    epochs=EPOCHS, \n",
        "                    callbacks=callbacks,\n",
        "                    validation_data = val_gen,\n",
        "                    validation_steps=len(df_val) / BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Plotting the trends of train vs validation loss, dice_coeff and iou with respect to increase in number of epochs for the unet model with attention***"
      ],
      "metadata": {
        "id": "vKVJIiK2HpOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8VdmnWZ3C_1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,15))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(model_att.history.history['loss'], 'b-', label='train_loss')\n",
        "plt.plot(model_att.history.history['val_loss'], 'r-', label='val_loss')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')\n",
        "# Save the figure as an image file\n",
        "plt.savefig('loss.png')  # specify the file name and extension\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(model_att.history.history['iou'], 'b-', label='train_iou')\n",
        "plt.plot(model_att.history.history['val_iou'], 'r-', label='val_iou')\n",
        "plt.legend(loc='best')\n",
        "plt.title('IoU')\n",
        "# Save the figure as an image file\n",
        "plt.savefig('iou.png')  # specify the file name and extension\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(model_att.history.history['dice_coef'], 'b-', label='train_dice_coef')\n",
        "plt.plot(model_att.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Dice Coef')\n",
        "# Save the figure as an image file\n",
        "plt.savefig('dice_coeff.png')  # specify the file name and extension"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Loading the best weights of model with attention***"
      ],
      "metadata": {
        "id": "dzaAyzFiIk35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0qjGv0azKNN"
      },
      "outputs": [],
      "source": [
        "model_att.load_weights(\"/content/data/unet_brainMRI_att.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluation of Model with Attention***"
      ],
      "metadata": {
        "id": "bqP34RYrH2Y0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydw9lQac5eyK"
      },
      "outputs": [],
      "source": [
        "test_gen = train_generator(df_test, BATCH_SIZE, dict())\n",
        "results = model_att.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\n",
        "print(\"Test IOU: \",results[1])\n",
        "print(\"Test Dice Coefficent: \",results[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og8C1VBJSyGY"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    index=np.random.randint(1,len(df_test.index))\n",
        "    img = cv2.imread(df_test['image_path'].iloc[index])\n",
        "    img = cv2.resize(img ,IMAGE_SIZE)\n",
        "    img = img / 255\n",
        "    img = img[np.newaxis, :, :, :]\n",
        "    pred = model_att.predict(img)\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(np.squeeze(img))\n",
        "    plt.title('Original Image')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n",
        "    plt.title('Original Mask')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(np.squeeze(pred) > .5)\n",
        "    plt.title('Prediction')\n",
        "    # Save the figure as an image with a unique filename\n",
        "    plt.savefig(f'prediction_{i+1}.png')  # Specify a unique filename for each figure\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}